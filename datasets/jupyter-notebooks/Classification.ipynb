{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pull_data import Pull\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from prettytable import PrettyTable\n",
    "from statistics import mean\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of available classess in dataset\n",
    "# Uncomment any class to include it into evaluation\n",
    "DATA_CLASS = {\n",
    "    # CESNET DATASET\n",
    "    \"IKEA_APP\" : \"dev-annotated-datasets/ikea-app/train\",\n",
    "    \"IKEA_HOMEKIT_CLEAR\" : \"dev-annotated-datasets/ikea-app/anomaly\",\n",
    "#    \"IKEA_HOMEKIT\" : \"dev-annotated-datasets/ikea-homekit/train\",\n",
    "    \"IP_CAM\" : \"dev-annotated-datasets/ipcam/train\",\n",
    "#    \"IP_CAM_MISCONFIG\" : \"dev-annotated-datasets/ipcam/anomaly_cam\",\n",
    "    \"NORMAL_USER\" : \"dev-annotated-datasets/normal-user/train\",\n",
    "    \"VOICE_ASSISTANT\" : \"dev-annotated-datasets/voice-assistant/train\",\n",
    "    \n",
    "    # UNSW DATASET (https://iotanalytics.unsw.edu.au/iottraces)\n",
    "    ## HUBS\n",
    "    \"AMAZON_ECHO\" : \"../data-sets/unsw-traces-device/Amazon-Echo\",\n",
    "    \"SMART_THINGS\" : \"../data-sets/unsw-traces-device/Smart-Things\",\n",
    "    ## CAMERAS\n",
    "    \"NETAMO_WELCOME\" : \"../data-sets/unsw-traces-device/Netatmo-Welcome\",\n",
    "    #\"TP-Link-Day-Night-Cloud-Camera\" : \"../data-sets/unsw-traces-device/TP-Link-Day-Night-Cloud-Camera\",\n",
    "    \"Samsung-Smart-Cam\" : \"../data-sets/unsw-traces-device/Samsung-Smart-Cam\",\n",
    "    \"INSTEON_CAM\" : \"../data-sets/unsw-traces-device/Insteon-Camera\",\n",
    "    #\"DROP_CAM\" : \"../data-sets/unsw-traces-device/Dropcam\",\n",
    "    \"WITHINGS_SMART_BABY_MONITOR\" : \"../data-sets/unsw-traces-device/Withings-Smart-Baby-Monitor\",\n",
    "    ## SWITCHES AND TRIGGERS\n",
    "    \"BELKIN_WEMO_SWITCH\" : \"../data-sets/unsw-traces-device/Belkin-Wemo-Switch\",\n",
    "    \"TP-Link-Smart-Plug\" : \"../data-sets/unsw-traces-device/TP-Link-Smart-Plug\",\n",
    "    #\"iHome\" : \"../data-sets/unsw-traces-device/iHome\", -> not available in recorded first week\n",
    "    \"BELKIN_WEMO_MOTION_SENSOR\" : \"../data-sets/unsw-traces-device/Belkin-Wemo-Motion-Sensor\",\n",
    "    ## AIR QUALITY SENSORS\n",
    "    #\"NEST-Protect-Smoke-Alarm\" : \"../data-sets/unsw-traces-device/NEST-Protect-Smoke-Alarm\", not available in recorded first one week\n",
    "    \"Netatmo-Weather-Station\" : \"../data-sets/unsw-traces-device/Netatmo-Weather-Station\",\n",
    "    ## HEATLTHCARE DEVICE\n",
    "    #\"Withings-Smart-Scale\" : \"../data-sets/unsw-traces-device/Withings-Smart-Scale\", -> not available in recorded first one week\n",
    "    #\"Blipcare-Blood-Pressure-Meter\" : \"../data-sets/unsw-traces-device/Blipcare-Blood-Pressure-Meter\", -> not available in recorded first one week\n",
    "    \"Withings-Aura-Smart-Sleep-Sensor\" : \"../data-sets/unsw-traces-device/Withings-Aura-Smart-Sleep-Sensor\",\n",
    "    ## LIGHT BULBS\n",
    "    \"Light-Bulbs-LiFX-Smart-Bulb\" : \"../data-sets/unsw-traces-device/Light-Bulbs-LiFX-Smart-Bulb\",\n",
    "    ## ELECTRONIC\n",
    "    #\"Triby-Speaker\" : \"../data-sets/unsw-traces-device/Triby-Speaker\", -> not available in recorded first one week\n",
    "    #\"PIX-STAR-Photo-Frame\" : \"../data-sets/unsw-traces-device/PIX-STAR-Photo-Frame\", -> not available in recorded first one week\n",
    "    \"HP-Printer\" : \"../data-sets/unsw-traces-device/HP-Printer\",\n",
    "    ## NON-IOT\n",
    "    \"Laptop\" : \"../data-sets/unsw-traces-device/Laptop\",\n",
    "    \"ANDROID_PHONE\" : \"../data-sets/unsw-traces-device/Android-Phone\",\n",
    "    \"Samsung-Galaxy-Tab\" : \"../data-sets/unsw-traces-device/Samsung-Galaxy-Tab\",\n",
    "    #\"IPhone\" : \"../data-sets/unsw-traces-device/IPhone\", -> not available in recorded first one week\n",
    "    \n",
    "    # CTU13 BOTNET ATTACKS DATASET (https://www.stratosphereips.org/datasets-ctu13)\n",
    "#    \"BOTNET_SOGOU\" : \"../data-sets/botnet/sogou\",\n",
    "#    \"BOTNET_RBOT\" : \"../data-sets/botnet/rbot\",\n",
    "#    \"BOTNET_NERIS\" : \"../data-sets/botnet/neris\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic initial evaluation of different models\n",
    "def runModel(models):\n",
    "    for key, model in models.items():\n",
    "        print(\"### Model Name:\",key,\" ###\")\n",
    "        kf = KFold(5, True)\n",
    "        iteration_cnt = 0\n",
    "        for train_index, test_index in kf.split(c_data,c_target):\n",
    "            iteration_cnt += 1\n",
    "            #Train\n",
    "            model.fit(c_data[train_index],c_target[train_index])\n",
    "            #Evaluate \n",
    "            p_class = model.predict(c_data[test_index])\n",
    "            y_pred_valid = model.predict_proba(c_data[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test pull to verify initial classification results \n",
    "a = Pull(VOICE_ASSISTANT +\"/train/\",1)\n",
    "b = Pull(IKEA_APP +\"/train/\",2)\n",
    "c = Pull(IKEA_HOMEKIT +\"/train/\",2)\n",
    "d = Pull(IP_CAM +\"/train/\",3)\n",
    "e = Pull(NORMAL_USER +\"/train/\",4)\n",
    "c_anomaly = np.array(Pull(IP_CAM+\"/anomaly\",3).data)\n",
    "c_data = np.array(a.data + b.data)# + c.data + d.data)# + e.data)\n",
    "c_target = np.array(a.labels + b.labels)# + c.labels + d.labels)# + e.labels)\n",
    "print(\"Input Data:\",len(c_data),\" Input Labels:\",len(c_target))\n",
    "print(\"Number of features:\",a.features_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {}\n",
    "MODELS[\"RandomForest\"] = {}\n",
    "MODELS[\"AdaBoost\"] = {}\n",
    "MODELS[\"GradientBoosting\"] = {}\n",
    "rng = np.random.RandomState(12345)\n",
    "\n",
    "MODELS[\"RandomForest\"][\"RF1\"] = RandomForestClassifier(random_state=rng,n_estimators=10)\n",
    "MODELS[\"AB1\"] = AdaBoostClassifier(random_state=rng)\n",
    "MODELS[\"GradientBoosting\"] = GradientBoostingClassifier(random_state=rng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run specific set of models based on above definition\n",
    "#runModel(MODELS[\"RandomForest\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Generates results for experiments section in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading IKEA_APP  dataset\n",
      "Loading Anomaly IKEA_HOMEKIT_CLEAR  dataset\n",
      "Loading IP_CAM  dataset\n",
      "Loading NORMAL_USER  dataset\n",
      "Loading VOICE_ASSISTANT  dataset\n",
      "Loading AMAZON_ECHO  dataset\n",
      "Loading SMART_THINGS  dataset\n",
      "Loading NETAMO_WELCOME  dataset\n",
      "Loading Samsung-Smart-Cam  dataset\n",
      "Loading INSTEON_CAM  dataset\n",
      "Loading WITHINGS_SMART_BABY_MONITOR  dataset\n",
      "Loading BELKIN_WEMO_SWITCH  dataset\n",
      "Loading TP-Link-Smart-Plug  dataset\n",
      "Loading BELKIN_WEMO_MOTION_SENSOR  dataset\n",
      "Loading Netatmo-Weather-Station  dataset\n",
      "Loading Withings-Aura-Smart-Sleep-Sensor  dataset\n",
      "Loading Light-Bulbs-LiFX-Smart-Bulb  dataset\n",
      "Loading HP-Printer  dataset\n",
      "Loading Laptop  dataset\n",
      "Loading ANDROID_PHONE  dataset\n",
      "Loading Samsung-Galaxy-Tab  dataset\n"
     ]
    }
   ],
   "source": [
    "UPPER_LIMIT = 400 # set upper limit for flows training dataset\n",
    "ANOMALY = [\"IKEA_HOMEKIT_CLEAR\"]\n",
    "class_index = 1\n",
    "c_data = None\n",
    "c_target = None\n",
    "c_anomaly_data = None\n",
    "c_anomaly_target = None\n",
    "\n",
    "for data_cl in DATA_CLASS: \n",
    "    \n",
    "    # Pull anomaly classes\n",
    "    if data_cl in ANOMALY:\n",
    "        print(\"Loading Anomaly\",data_cl,\" dataset\")\n",
    "        a = Pull(DATA_CLASS[data_cl],999)\n",
    "        # Set upper limit due to possible unbiased results\n",
    "        if len(a.data) < UPPER_LIMIT:\n",
    "            max_limit = len(a.data)\n",
    "        else:\n",
    "            max_limit = UPPER_LIMIT\n",
    "        # uniform random sample\n",
    "        idx = np.random.choice(len(a.data), max_limit, replace=False)\n",
    "        \n",
    "        if c_anomaly_data is None:\n",
    "            c_anomaly_data = np.array(a.data)[idx]\n",
    "            c_anomaly_target = np.array(a.labels)[idx]\n",
    "        else:\n",
    "            c_anomaly_data = np.concatenate((c_anomaly_data,np.array(a.data)[idx]))\n",
    "            c_anomaly_target = np.concatenate((c_anomaly_target,np.array(a.labels)[idx]),axis=None)\n",
    "        continue\n",
    "        \n",
    "    # Pull valid classes \n",
    "    a = Pull(DATA_CLASS[data_cl],class_index)\n",
    "    # Set upper limit due to possible unbiased results\n",
    "    if len(a.data) < UPPER_LIMIT:\n",
    "        max_limit = len(a.data)\n",
    "    else:\n",
    "        max_limit = UPPER_LIMIT\n",
    "    # uniform random sample\n",
    "    idx = np.random.choice(len(a.data), max_limit, replace=False)\n",
    "        \n",
    "    print(\"Loading\",data_cl,\" dataset\")\n",
    "    if c_data is None:\n",
    "        c_data = np.array(a.data)[idx]\n",
    "        c_target = np.array(a.labels)[idx]\n",
    "    else:\n",
    "        c_data = np.concatenate((c_data,np.array(a.data)[idx]))\n",
    "        c_target = np.concatenate((c_target,np.array(a.labels)[idx]),axis=None)\n",
    "        \n",
    "    class_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate format of structure for evaluation  \n",
    "def createResultDict(no_classes):\n",
    "    tmp_struct = {}\n",
    "    for i in range(no_classes):\n",
    "        tmp_struct[i+1] = {}\n",
    "        for j in range(no_classes):\n",
    "            tmp_struct[i+1][j+1] = 0\n",
    "    return tmp_struct\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : {1: 0.9936032957486792, 2: 0, 3: 0.007352941176470588, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0.012281494876431584, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0.012658227848101266}\n",
      "2 : {1: 0.030509935773093667, 2: 0.6197546358730569, 3: 0.012469287469287469, 4: 0.019079229605545395, 5: 0.33791674877201194, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0.006756756756756757, 18: 0, 19: 0.008771929824561403, 20: 0.00909090909090909}\n",
      "3 : {1: 0.02125506072874494, 2: 0.0058823529411764705, 3: 0.8790877788362308, 4: 0.01282051282051282, 5: 0.016443895371913948, 6: 0, 7: 0.01636302294197031, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0.00641025641025641, 17: 0, 18: 0.012767424783678653, 19: 0.04742299753909661, 20: 0.012593276176867507}\n",
      "4 : {1: 0.03595627242939616, 2: 0.03636162687886826, 3: 0.012558836531960264, 4: 0.8184491535340928, 5: 0.039109390440526345, 6: 0.014705882352941176, 7: 0.018073542414313207, 8: 0, 9: 0.008620689655172414, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0.00641025641025641, 17: 0.00641025641025641, 18: 0, 19: 0.010720601237842617, 20: 0.010720601237842617}\n",
      "5 : {1: 0, 2: 0, 3: 0.005154639175257732, 4: 0.012401015986851935, 5: 0.8859601285562919, 6: 0.01880856709692292, 7: 0.05138105844679104, 8: 0, 9: 0.025586591878832356, 10: 0, 11: 0, 12: 0.009046402724563644, 13: 0, 14: 0, 15: 0.022727272727272728, 16: 0, 17: 0, 18: 0, 19: 0.01964739279844614, 20: 0}\n",
      "6 : {1: 0, 2: 0, 3: 0, 4: 0, 5: 0.015151515151515152, 6: 0.687541626152161, 7: 0.03784076966813299, 8: 0, 9: 0.03880292284547604, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0.24337559548516577, 17: 0, 18: 0, 19: 0, 20: 0.012658227848101266}\n",
      "7 : {1: 0.005376344086021506, 2: 0, 3: 0.017006478347907174, 4: 0.03404811219293781, 5: 0.11303796914715143, 6: 0.028862396012615858, 7: 0.7406895703877225, 8: 0, 9: 0.047119420005840074, 10: 0, 11: 0, 12: 0.024524777042304637, 13: 0, 14: 0, 15: 0, 16: 0.01310310524435731, 17: 0.005154639175257732, 18: 0, 19: 0.011576852079447473, 20: 0.007246376811594203}\n",
      "8 : {1: 0, 2: 0, 3: 0, 4: 0, 5: 0.127332042622415, 6: 0.007042253521126761, 7: 0, 8: 0.6848047465643452, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0.1334035728136635, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0.05269907461929457, 19: 0, 20: 0}\n",
      "9 : {1: 0, 2: 0, 3: 0.006172839506172839, 4: 0.013315696649029981, 5: 0.0049504950495049506, 6: 0.04224465856658028, 7: 0.07689139829015582, 8: 0, 9: 0.8062310862417941, 10: 0, 11: 0, 12: 0.013018839961727265, 13: 0, 14: 0, 15: 0.007352941176470588, 16: 0.020429303230276342, 17: 0, 18: 0, 19: 0.007142857142857143, 20: 0.019202240164492637}\n",
      "10 : {1: 0, 2: 0, 3: 0.012658227848101266, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0.9992088607594937, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0}\n",
      "11 : {1: 0, 2: 0.012196935891715008, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0.006024096385542169, 8: 0, 9: 0, 10: 0, 11: 0.7403642347166444, 12: 0, 13: 0.2558149263721553, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0.012345679012345678, 19: 0, 20: 0.012345679012345678}\n",
      "12 : {1: 0, 2: 0, 3: 0, 4: 0.03131808278867103, 5: 0.04028132992327366, 6: 0, 7: 0.06601366391967416, 8: 0, 9: 0.09726366391967414, 10: 0, 11: 0, 12: 0.7358624609263995, 13: 0, 14: 0, 15: 0, 16: 0.047314578005115085, 17: 0, 18: 0, 19: 0, 20: 0.021739130434782608}\n",
      "13 : {1: 0, 2: 0.005747126436781609, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0.12182617004446245, 9: 0, 10: 0, 11: 0.5139846040368596, 12: 0, 13: 0.3372698384581356, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0.021532510815694565, 19: 0.00684931506849315, 20: 0}\n",
      "14 : {1: 0.01190644932671864, 2: 0, 3: 0, 4: 0.00625, 5: 0.010920581058410858, 6: 0, 7: 0.006329113924050633, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0.9814948097554489, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0.00684931506849315, 20: 0}\n",
      "15 : {1: 0.0125, 2: 0, 3: 0, 4: 0, 5: 0.00625, 6: 0, 7: 0.0058823529411764705, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0.9805985041834855, 16: 0, 17: 0.009743504330446368, 18: 0.006578947368421052, 19: 0, 20: 0}\n",
      "16 : {1: 0, 2: 0, 3: 0, 4: 0, 5: 0.005952380952380952, 6: 0.24044601012346364, 7: 0.011699507389162561, 8: 0, 9: 0.04912753900031262, 10: 0, 11: 0, 12: 0.010246398716226303, 13: 0, 14: 0.005747126436781609, 15: 0, 16: 0.6852557899260103, 17: 0, 18: 0, 19: 0.0136986301369863, 20: 0}\n",
      "17 : {1: 0.01105592236894758, 2: 0.01705339670114621, 3: 0, 4: 0.016594345527315736, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0.005813953488372093, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0.005813953488372093, 16: 0, 17: 0.9533477454377737, 18: 0.01245498199279712, 19: 0.006666666666666667, 20: 0}\n",
      "18 : {1: 0.005681818181818182, 2: 0.005813953488372093, 3: 0.05320564220494706, 4: 0.010466456782179735, 5: 0.05511025774865512, 6: 0, 7: 0.008654862579281185, 8: 0.0897305014247633, 9: 0, 10: 0.005681818181818182, 11: 0.02086038961038961, 12: 0.017999660223497433, 13: 0.0350519677491366, 14: 0, 15: 0.005681818181818182, 16: 0.006493506493506494, 17: 0.01830689532914002, 18: 0.6165043358436306, 19: 0.04763666565992147, 20: 0.043148794614132076}\n",
      "19 : {1: 0.019045893719806764, 2: 0, 3: 0.055712775384753443, 4: 0.030610286639446014, 5: 0.17136276192399158, 6: 0.017536231884057972, 7: 0.02046552736273762, 8: 0.013053246660983234, 9: 0.013333333333333334, 10: 0.009171826625386997, 11: 0, 12: 0.005434782608695652, 13: 0, 14: 0.010335855356635407, 15: 0.0058823529411764705, 16: 0.005434782608695652, 17: 0, 18: 0.02568577907898476, 19: 0.5778562007373507, 20: 0.0738126626508727}\n",
      "20 : {1: 0.005747126436781609, 2: 0.006944444444444444, 3: 0.049772600514088945, 4: 0.026103927203065133, 5: 0.07179394611765846, 6: 0, 7: 0.012691570881226053, 8: 0, 9: 0.013611111111111112, 10: 0.016163793103448273, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0.012835339977690478, 16: 0.011494252873563218, 17: 0.009801336146272856, 18: 0.020296980333672825, 19: 0.07198795710267229, 20: 0.736225053348853}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.93      0.96        94\n",
      "           2       0.68      0.88      0.77        49\n",
      "           3       0.88      0.80      0.84        84\n",
      "           4       0.78      0.81      0.80        75\n",
      "           5       0.90      0.55      0.69       157\n",
      "           6       0.67      0.65      0.66        68\n",
      "           7       0.71      0.74      0.73        70\n",
      "           8       0.66      0.74      0.70        69\n",
      "           9       0.80      0.76      0.78        74\n",
      "          10       1.00      0.97      0.99        75\n",
      "          11       0.72      0.61      0.66        99\n",
      "          12       0.79      0.79      0.79        34\n",
      "          13       0.30      0.35      0.32        63\n",
      "          14       0.99      0.99      0.99        73\n",
      "          15       0.97      0.99      0.98        75\n",
      "          16       0.65      0.72      0.69        76\n",
      "          17       0.96      0.96      0.96        75\n",
      "          18       0.62      0.87      0.72        61\n",
      "          19       0.60      0.77      0.68        66\n",
      "          20       0.76      0.84      0.80        79\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1516\n",
      "   macro avg       0.77      0.79      0.77      1516\n",
      "weighted avg       0.79      0.77      0.77      1516\n",
      "\n",
      "Cross-validation score: [0.76695194 0.77272727 0.77916941 0.77425743 0.76831683]\n",
      "Total classification accuracy: 0.7737467018469657\n",
      "===================\n",
      "0.0625\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(12345)\n",
    "model = RandomForestClassifier(random_state=rng,n_estimators=10)\n",
    "\n",
    "kf = KFold(5, True)\n",
    "iteration_cnt = 0\n",
    "\n",
    "# Generate struct for defined number of input classes\n",
    "result_struct = createResultDict(20)\n",
    "\n",
    "# Split dataset \n",
    "for train_index, test_index in kf.split(c_data,c_target):\n",
    "    tmp_result_struct = {}\n",
    "    iteration_cnt += 1\n",
    "    # Train\n",
    "    model.fit(c_data[train_index],c_target[train_index])\n",
    "    # Evaluate \n",
    "    y_class = model.predict(c_data[test_index])\n",
    "    y_pred = model.predict_proba(c_data[test_index])\n",
    "    \n",
    "    # Count classification frequency\n",
    "    for i in range(len(test_index)):\n",
    "        try:\n",
    "            tmp_result_struct[c_target[test_index[i]]][y_class[i]] += 1\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                tmp_result_struct[c_target[test_index[i]]][y_class[i]] = 1\n",
    "            except Exception as e3:\n",
    "                tmp_result_struct[c_target[test_index[i]]] = {}\n",
    "                tmp_result_struct[c_target[test_index[i]]][y_class[i]] = 1\n",
    "                \n",
    "    # Create classification frequency in percentage\n",
    "    for t_class,t_value in tmp_result_struct.items():\n",
    "        p_sum = 0\n",
    "        for p_class,p_value in t_value.items():\n",
    "            p_sum += p_value\n",
    "        for p_class,p_value in t_value.items():\n",
    "            if iteration_cnt == 1:\n",
    "                result_struct[t_class][p_class] = (p_value/p_sum)\n",
    "            else:\n",
    "                result_struct[t_class][p_class] = (result_struct[t_class][p_class]+(p_value/p_sum))/2\n",
    "\n",
    "# print classification frequency results\n",
    "for key,val in result_struct.items():\n",
    "    print(key,\":\",val)\n",
    "  \n",
    "print(classification_report(y_class,c_target[test_index],output_dict=False))\n",
    "print(\"Cross-validation score:\",cross_val_score(model, c_data, c_target, cv=5))\n",
    "print(\"Total classification accuracy:\",metrics.accuracy_score(y_class,c_target[test_index]))\n",
    "print(\"===================\")\n",
    "# Predict class for anomaly (unknown) traffic\n",
    "y_class = model.predict(c_anomaly_data)\n",
    "y_pred = model.predict_proba(c_anomaly_data)\n",
    "# Measure accuracy (classification frequency) against defined classess\n",
    "print(metrics.accuracy_score(y_class,[1]*len(c_anomaly_data.data)))\n",
    "print(metrics.accuracy_score(y_class,[2]*len(c_anomaly_data.data)))\n",
    "print(metrics.accuracy_score(y_class,[3]*len(c_anomaly_data.data)))\n",
    "print(metrics.accuracy_score(y_class,[4]*len(c_anomaly_data.data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below models don't have sufficient results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rng = np.random.RandomState(12345)\n",
    "model = AdaBoostClassifier(random_state=rng)\n",
    "\n",
    "kf = KFold(3, True)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(c_data,c_target):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    model.fit(c_data[train_index],c_target[train_index])\n",
    "    #Evaluate \n",
    "    y_class = model.predict(c_data[test_index])\n",
    "    y_pred = model.predict_proba(c_data[test_index])\n",
    "    #print(metrics.accuracy_score(y_class,c_target[test_index]))\n",
    "    print(classification_report(y_class,c_target[test_index],output_dict=False))\n",
    "\n",
    "print(cross_val_score(model, c_data, c_target, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoosting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rng = np.random.RandomState(12345)\n",
    "model = GradientBoostingClassifier(random_state=rng)\n",
    "\n",
    "kf = KFold(3, True)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(c_data,c_target):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    model.fit(c_data[train_index],c_target[train_index])\n",
    "    #Evaluate \n",
    "    y_class = model.predict(c_data[test_index])\n",
    "    y_pred = model.predict_proba(c_data[test_index])\n",
    "    #print(metrics.accuracy_score(y_class,c_target[test_index]))\n",
    "    print(classification_report(y_class,c_target[test_index],output_dict=False))\n",
    "\n",
    "print(cross_val_score(model, c_data, c_target, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
