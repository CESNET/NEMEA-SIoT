{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pull_data import Pull\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from prettytable import PrettyTable\n",
    "from statistics import mean\n",
    "\n",
    "#from scikit_IsolatedForest import IsolatedForest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "#from scikit_LOFNovelty import LOFNovelty\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "#from scikit_OneClassSVM import OCSVM\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of available classess in dataset\n",
    "# Uncomment any class to include it into evaluation\n",
    "DATA_CLASS = {\n",
    "    # CESNET DATASET\n",
    "    \"IKEA_APP\" : \"dev-annotated-datasets/ikea-app/train\",\n",
    "    \"IKEA_HOMEKIT_CLEAR\" : \"dev-annotated-datasets/ikea-app/anomaly\",\n",
    "    #\"IKEA_HOMEKIT\" : \"dev-annotated-datasets/ikea-homekit/train\",\n",
    "    \"IP_CAM\" : \"dev-annotated-datasets/ipcam/train\",\n",
    "    \"IP_CAM_MISCONFIG\" : \"dev-annotated-datasets/ipcam/anomaly_cam\",\n",
    "    \"NORMAL_USER\" : \"dev-annotated-datasets/normal-user/train\",\n",
    "    \"VOICE_ASSISTANT\" : \"dev-annotated-datasets/voice-assistant/train\",\n",
    "    \n",
    "    # UNSW DATASET\n",
    "    ## HUBS\n",
    "#    \"AMAZON_ECHO\" : \"../data-sets/unsw-traces-device/Amazon-Echo\",\n",
    "#    \"SMART_THINGS\" : \"../data-sets/unsw-traces-device/Smart-Things\",\n",
    "    ## CAMERAS\n",
    "#    \"NETAMO_WELCOME\" : \"../data-sets/unsw-traces-device/Netatmo-Welcome\",\n",
    "    #\"TP-Link-Day-Night-Cloud-Camera\" : \"../data-sets/unsw-traces-device/TP-Link-Day-Night-Cloud-Camera\",\n",
    "#    \"Samsung-Smart-Cam\" : \"../data-sets/unsw-traces-device/Samsung-Smart-Cam\",\n",
    "#    \"INSTEON_CAM\" : \"../data-sets/unsw-traces-device/Insteon-Camera\",\n",
    "    #\"DROP_CAM\" : \"../data-sets/unsw-traces-device/Dropcam\",\n",
    "#    \"WITHINGS_SMART_BABY_MONITOR\" : \"../data-sets/unsw-traces-device/Withings-Smart-Baby-Monitor\",\n",
    "    ## SWITCHES AND TRIGGERS\n",
    "#    \"BELKIN_WEMO_SWITCH\" : \"../data-sets/unsw-traces-device/Belkin-Wemo-Switch\",\n",
    "#    \"TP-Link-Smart-Plug\" : \"../data-sets/unsw-traces-device/TP-Link-Smart-Plug\",\n",
    "    #\"iHome\" : \"../data-sets/unsw-traces-device/iHome\",\n",
    "#    \"BELKIN_WEMO_MOTION_SENSOR\" : \"../data-sets/unsw-traces-device/Belkin-Wemo-Motion-Sensor\",\n",
    "    ## AIR QUALITY SENSORS\n",
    "    #\"NEST-Protect-Smoke-Alarm\" : \"../data-sets/unsw-traces-device/NEST-Protect-Smoke-Alarm\",\n",
    "#    \"Netatmo-Weather-Station\" : \"../data-sets/unsw-traces-device/Netatmo-Weather-Station\",\n",
    "    ## HEATLTHCARE DEVICE\n",
    "    #\"Withings-Smart-Scale\" : \"../data-sets/unsw-traces-device/Withings-Smart-Scale\",\n",
    "    #\"Blipcare-Blood-Pressure-Meter\" : \"../data-sets/unsw-traces-device/Blipcare-Blood-Pressure-Meter\",\n",
    "#    \"Withings-Aura-Smart-Sleep-Sensor\" : \"../data-sets/unsw-traces-device/Withings-Aura-Smart-Sleep-Sensor\",\n",
    "    ## LIGHT BULBS\n",
    "#    \"Light-Bulbs-LiFX-Smart-Bulb\" : \"../data-sets/unsw-traces-device/Light-Bulbs-LiFX-Smart-Bulb\",\n",
    "    ## ELECTRONIC\n",
    "    #\"Triby-Speaker\" : \"../data-sets/unsw-traces-device/Triby-Speaker\",\n",
    "    #\"PIX-STAR-Photo-Frame\" : \"../data-sets/unsw-traces-device/PIX-STAR-Photo-Frame\",\n",
    "#    \"HP-Printer\" : \"../data-sets/unsw-traces-device/HP-Printer\",\n",
    "    ## NON-IOT\n",
    "#    \"Laptop\" : \"../data-sets/unsw-traces-device/Laptop\",\n",
    "#    \"ANDROID_PHONE\" : \"../data-sets/unsw-traces-device/Android-Phone\",\n",
    "#    \"Samsung-Galaxy-Tab\" : \"../data-sets/unsw-traces-device/Samsung-Galaxy-Tab\",\n",
    "    #\"IPhone\" : \"../data-sets/unsw-traces-device/IPhone\",\n",
    "    \n",
    "    # CTU13 BOTNET ATTACKS DATASET\n",
    "    \"BOTNET_SOGOU\" : \"../data-sets/botnet/sogou\",\n",
    "    \"BOTNET_RBOT\" : \"../data-sets/botnet/rbot\",\n",
    "    \"BOTNET_NERIS\" : \"../data-sets/botnet/neris\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self,label):\n",
    "        self.label = label\n",
    "        self.accuracy = []\n",
    "        self.precision = []\n",
    "        self.recall = []\n",
    "        self.f1 = []\n",
    "        self.cnt = 0\n",
    "    def update(self,y,pred,score):\n",
    "        try:\n",
    "            tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "        except Exception as e:\n",
    "            # TN in all cases\n",
    "            tn = 0\n",
    "            fp = 0\n",
    "            fn = 0\n",
    "            tp = confusion_matrix(y, pred).ravel()[0]\n",
    "        \n",
    "        total = tp+tn+fp+fn\n",
    "        accuracy = (tp+tn)/total\n",
    "        if self.label == \"Valid\" or self.label == \"Mix\":\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            f1 = 2*(precision*recall)/(precision+recall)\n",
    "        else:\n",
    "            try:\n",
    "                precision = tn/(tn+fn) # Negative precision\n",
    "                recall = tn/(tn+fp) # Negative recall\n",
    "                f1 = 2*(precision*recall)/(precision+recall) # Negative f1\n",
    "            except Exception as e:\n",
    "                print(\"ERROR\",self.label,e)\n",
    "                precision = 0\n",
    "                f1 = 0\n",
    "                recall = 0\n",
    "        self.accuracy.append(accuracy)\n",
    "        self.precision.append(precision)\n",
    "        self.recall.append(recall)\n",
    "        self.f1.append(f1)\n",
    "        self.cnt += 1\n",
    "        \n",
    "    def print(self):\n",
    "        table = PrettyTable()\n",
    "        table.field_names = [self.label+\" Data\",\"Accuracy\", \"Precision\", \"Recall\", \"F1 score\"]\n",
    "        for i in range(len(self.accuracy)):\n",
    "            table.add_row([i,round(self.accuracy[i],3),round(self.precision[i],3),round(self.recall[i],3),round(self.f1[i],3)])\n",
    "        \n",
    "        table.add_row([\"Avg\",round(mean(self.accuracy),3),round(mean(self.precision),3),round(mean(self.recall),3),round(mean(self.f1),3)])\n",
    "        print(table)\n",
    "        # Return F1-score\n",
    "        return round(mean(self.f1),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y, pred, thr_pred=0.5, label=\"\"):\n",
    "    print(\"### Metric\",label,\"###\")\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "    except Exception as e:\n",
    "        # TP in all cases\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tp = confusion_matrix(y, pred).ravel()[0]\n",
    "    #print(tn, fp, fn, tp)\n",
    "    \n",
    "    total = tp+tn+fp+fn\n",
    "    acc = (tp+tn)/total\n",
    "    if label == \"Valid\" or label == \"Mix\":\n",
    "        prec = tp/(tp+fp)\n",
    "        rec = tp/(tp+fn)\n",
    "        f1 = 2*(prec*rec)/(prec+rec)\n",
    "    \n",
    "        print(\"TP: {:7d} {:6.2f}%\".format(tp, tp*100/total))\n",
    "        print(\"FN: {:7d} {:6.2f}%\".format(fn, fn*100/total))\n",
    "        print(\"FP: {:7d} {:6.2f}%\".format(fp, fp*100/total))\n",
    "        print(\"TN: {:7d} {:6.2f}%\".format(tn, tn*100/total))\n",
    "        print(\"Accuracy:   {:6.2f}%\".format(acc*100))\n",
    "        print(\"Precision:  {:6.4f}\".format(prec))\n",
    "        print(\"Recall:     {:6.4f}\".format(rec))\n",
    "        print(\"F1 score:   {:6.4f}\".format(f1))\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            prec_n = tn/(tn+fn)\n",
    "            rec_n = tn/(tn+fp)\n",
    "            f1_n = 2*(prec_n*rec_n)/(prec_n+rec_n)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            prec_n = 0\n",
    "            f1_n = 0\n",
    "            rec_n = 0\n",
    "        \n",
    "        print(\"TP: {:7d} {:6.2f}%\".format(tp, tp*100/total))\n",
    "        print(\"FN: {:7d} {:6.2f}%\".format(fn, fn*100/total))\n",
    "        print(\"FP: {:7d} {:6.2f}%\".format(fp, fp*100/total))\n",
    "        print(\"TN: {:7d} {:6.2f}%\".format(tn, tn*100/total))\n",
    "        print(\"Accuracy:   {:6.2f}%\".format(acc*100))\n",
    "        print(\"Precision Anomaly:  {:6.4f}\".format(prec_n))\n",
    "        print(\"Recall Anomaly:     {:6.4f}\".format(rec_n))\n",
    "        print(\"F1 score Anomaly:   {:6.4f}\".format(f1_n))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(models):\n",
    "    UPPER_LIMIT = 400 # set upper limit for flows training dataset\n",
    "    for key, model in models.items():\n",
    "        print(\"### Model Name:\",key,\" ###\")\n",
    "        # Set label based on the type of dataset data.. \n",
    "        m_valid = Metrics(label=\"Valid\")\n",
    "        m_anomaly = Metrics(label=\"Anomaly\")\n",
    "        m_mix = Metrics(label=\"Mix\")\n",
    "        kf = KFold(5, True)\n",
    "        \n",
    "        # uniform random select for anomaly\n",
    "        if len(a.data) < UPPER_LIMIT:\n",
    "            max_limit = len(a.data)\n",
    "        else:\n",
    "            max_limit = UPPER_LIMIT\n",
    "        a_idx = np.random.choice(len(a.data), max_limit, replace=False)\n",
    "        \n",
    "        # uniform random select for valid\n",
    "        if len(t.data) < UPPER_LIMIT:\n",
    "            max_limit = len(t.data)\n",
    "        else:\n",
    "            max_limit = UPPER_LIMIT\n",
    "        t_idx = np.random.choice(len(t.data), max_limit, replace=False)\n",
    "        \n",
    "        t_data = np.array(t.data)[t_idx]\n",
    "        a_data = np.array(a.data)[a_idx]\n",
    "        print(len(t_data),len(a_data))\n",
    "        iteration_cnt = 0\n",
    "        for train_index, test_index in kf.split(t_data):\n",
    "            iteration_cnt += 1\n",
    "            #Train\n",
    "            model.fit(t_data[train_index])\n",
    "            #Evaluate \n",
    "            # Valid Evaluation\n",
    "            y_pred_valid = model.predict(t_data[test_index])\n",
    "            score_v = model.decision_function(t_data[test_index])\n",
    "            \n",
    "            #Anomaly Evaluation\n",
    "            if len(a.data) <= max(test_index):\n",
    "                y_pred_outliers = model.predict(a.data)\n",
    "                score_a = model.decision_function(a.data)\n",
    "            else:\n",
    "                y_pred_outliers = model.predict(a_data[test_index])\n",
    "                score_a = model.decision_function(a_data[test_index])\n",
    "            # Uncomment valid/anomaly in case you would like to evaluate these type of traffic separately\n",
    "            # Add results to the metrics object\n",
    "            #m_valid.update([1]*len(y_pred_valid),y_pred_valid,score_v)\n",
    "            #m_anomaly.update([-1]*len(y_pred_outliers),y_pred_outliers,score_a)\n",
    "            m_mix.update([1]*len(y_pred_valid) + [-1]*len(y_pred_outliers),np.concatenate((y_pred_valid,y_pred_outliers),axis=None),np.concatenate((score_v,score_a),axis=None))\n",
    "            \n",
    "            #print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"Valid\")\n",
    "            #print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"Anomaly\")\n",
    "        #m_valid.print()\n",
    "        #m_anomaly.print()\n",
    "        f1score = m_mix.print()\n",
    "        return f1score\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Demo test pull for initial tests\n",
    "t = Pull(DATA_CLASS[\"IKEA_APP\"],1) #+\"/train/\",1)\n",
    "#a = Pull(DATA_CLASS[\"NORMAL_USER\"] +\"/train/\",1)\n",
    "a = Pull(DATA_CLASS[\"INSTEON_CAM\"],1)\n",
    "#v = Pull(IKEA_APP +\"/valid/\",1)\n",
    "print(\"Valid:\",len(t.data),\" Anomaly:\",len(a.data))#,\" Valid:\",len(v.data))\n",
    "print(\"Number of features:\",t.features_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {}\n",
    "MODELS[\"IsolatedForest\"] = {}\n",
    "MODELS[\"LOF\"] = {}\n",
    "MODELS[\"OneClassSVM\"] = {}\n",
    "rng = np.random.RandomState(12345)\n",
    "MODELS[\"IsolatedForest\"][\"IF1\"] = IsolationForest(n_estimators = 250, max_samples='auto',max_features=5,bootstrap=True , behaviour='new',random_state=rng, contamination='auto')\n",
    "#MODELS[\"IsolatedForest\"][\"IF2\"] = IsolationForest(n_estimators = 20, max_samples='auto',max_features=5,bootstrap=True ,random_state=rng)\n",
    "#MODELS[\"LOF\"][\"LOF1\"] = LocalOutlierFactor(n_neighbors = 10, metric = \"chebyshev\", novelty=True, contamination=0.1)\n",
    "MODELS[\"LOF\"][\"LOF2\"] = LocalOutlierFactor(n_neighbors = 10, metric = \"chebyshev\", novelty=True, contamination='auto')\n",
    "#MODELS[\"LOF\"][\"LOF3\"] = LocalOutlierFactor(n_neighbors = 10, metric = \"canberra\", novelty=True, contamination='auto')\n",
    "#MODELS[\"LOF\"][\"LOF4\"] = LocalOutlierFactor(n_neighbors = 20, metric = \"euclidean\", novelty=True, contamination='auto')\n",
    "#MODELS[\"LOF\"][\"LOF5\"] = LocalOutlierFactor(n_neighbors = 20, metric = \"minkowski\", novelty=True, contamination='auto')\n",
    "#MODELS[\"LOF\"][\"LOF4\"] = LocalOutlierFactor(n_neighbors = 10, metric = \"canberra\", novelty=True, contamination='auto')\n",
    "MODELS[\"OneClassSVM\"][\"OSVM1\"] = OneClassSVM(kernel='poly',gamma=\"auto\",coef0=1, nu=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: 1027  Anomaly: 323\n",
      "Number of features: 32\n",
      "### Model Name: LOF2  ###\n",
      "400 323\n",
      "+----------+----------+-----------+--------+----------+\n",
      "| Mix Data | Accuracy | Precision | Recall | F1 score |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "|    0     |   0.65   |   0.348   | 0.875  |  0.498   |\n",
      "|    1     |  0.655   |   0.355   |  0.9   |  0.509   |\n",
      "|    2     |   0.64   |   0.335   | 0.825  |  0.477   |\n",
      "|    3     |   0.64   |   0.335   | 0.825  |  0.477   |\n",
      "|    4     |   0.63   |   0.321   | 0.775  |  0.454   |\n",
      "|   Avg    |  0.643   |   0.339   |  0.84  |  0.483   |\n",
      "+----------+----------+-----------+--------+----------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.483"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quickly compare two classes\n",
    "t = Pull(DATA_CLASS[\"NORMAL_USER\"],1)\n",
    "a = Pull(DATA_CLASS[\"IP_CAM\"],1)\n",
    "print(\"Valid:\",len(t.data),\" Anomaly:\",len(a.data))#,\" Valid:\",len(v.data))\n",
    "print(\"Number of features:\",t.features_cnt)\n",
    "runModel(MODELS[\"LOF\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Measurements for experiments section in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULST FOR CLASS: IKEA_APP\n",
      "### Model Name: LOF2  ###\n",
      "323 388\n",
      "+----------+----------+-----------+--------+----------+\n",
      "| Mix Data | Accuracy | Precision | Recall | F1 score |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "|    0     |  0.862   |   0.912   |  0.8   |  0.852   |\n",
      "|    1     |  0.877   |   0.962   | 0.785  |  0.864   |\n",
      "|    2     |  0.808   |    0.9    | 0.692  |  0.783   |\n",
      "|    3     |  0.906   |   0.981   | 0.828  |  0.898   |\n",
      "|    4     |  0.867   |   0.912   | 0.812  |   0.86   |\n",
      "|   Avg    |  0.864   |   0.934   | 0.784  |  0.851   |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "RESULST FOR CLASS: IKEA_HOMEKIT\n",
      "### Model Name: LOF2  ###\n",
      "323 192\n",
      "+----------+----------+-----------+--------+----------+\n",
      "| Mix Data | Accuracy | Precision | Recall | F1 score |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "|    0     |  0.907   |   0.815   | 0.815  |  0.815   |\n",
      "|    1     |  0.938   |    0.93   | 0.815  |  0.869   |\n",
      "|    2     |  0.907   |   0.918   | 0.692  |  0.789   |\n",
      "|    3     |   0.91   |   0.918   | 0.703  |  0.796   |\n",
      "|    4     |  0.941   |    0.93   | 0.828  |  0.876   |\n",
      "|   Avg    |  0.921   |   0.902   | 0.771  |  0.829   |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "RESULST FOR CLASS: IP_CAM\n",
      "### Model Name: LOF2  ###\n",
      "323 323\n",
      "+----------+----------+-----------+--------+----------+\n",
      "| Mix Data | Accuracy | Precision | Recall | F1 score |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "|    0     |  0.538   |   0.523   | 0.862  |  0.651   |\n",
      "|    1     |  0.523   |   0.515   |  0.8   |  0.627   |\n",
      "|    2     |  0.469   |    0.48   | 0.723  |  0.577   |\n",
      "|    3     |  0.461   |   0.476   | 0.766  |  0.587   |\n",
      "|    4     |   0.43   |   0.454   | 0.688  |  0.547   |\n",
      "|   Avg    |  0.484   |   0.489   | 0.768  |  0.598   |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "RESULST FOR CLASS: IP_CAM_MISCONFIG\n",
      "### Model Name: LOF2  ###\n",
      "323 400\n",
      "+----------+----------+-----------+--------+----------+\n",
      "| Mix Data | Accuracy | Precision | Recall | F1 score |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "|    0     |  0.846   |   0.846   | 0.846  |  0.846   |\n",
      "|    1     |  0.823   |   0.828   | 0.815  |  0.822   |\n",
      "|    2     |  0.808   |   0.803   | 0.815  |  0.809   |\n",
      "|    3     |  0.742   |   0.804   | 0.641  |  0.713   |\n",
      "|    4     |  0.758   |   0.851   | 0.625  |  0.721   |\n",
      "|   Avg    |  0.795   |   0.826   | 0.749  |  0.782   |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "RESULST FOR CLASS: NORMAL_USER\n",
      "### Model Name: LOF2  ###\n",
      "323 400\n",
      "+----------+----------+-----------+--------+----------+\n",
      "| Mix Data | Accuracy | Precision | Recall | F1 score |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "|    0     |  0.885   |   0.981   | 0.785  |  0.872   |\n",
      "|    1     |  0.854   |    1.0    | 0.708  |  0.829   |\n",
      "|    2     |  0.931   |   0.952   | 0.908  |  0.929   |\n",
      "|    3     |  0.867   |    1.0    | 0.734  |  0.847   |\n",
      "|    4     |  0.867   |   0.943   | 0.781  |  0.855   |\n",
      "|   Avg    |  0.881   |   0.975   | 0.783  |  0.866   |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "RESULST FOR CLASS: VOICE_ASSISTANT\n",
      "### Model Name: LOF2  ###\n",
      "323 332\n",
      "+----------+----------+-----------+--------+----------+\n",
      "| Mix Data | Accuracy | Precision | Recall | F1 score |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "|    0     |  0.885   |   0.963   |  0.8   |  0.874   |\n",
      "|    1     |   0.9    |   0.919   | 0.877  |  0.898   |\n",
      "|    2     |  0.769   |   0.889   | 0.615  |  0.727   |\n",
      "|    3     |  0.797   |   0.896   | 0.672  |  0.768   |\n",
      "|    4     |  0.836   |   0.906   |  0.75  |  0.821   |\n",
      "|   Avg    |  0.837   |   0.915   | 0.743  |  0.817   |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "RESULST FOR CLASS: BOTNET_SOGOU\n",
      "### Model Name: LOF2  ###\n",
      "323 47\n",
      "+----------+----------+-----------+--------+----------+\n",
      "| Mix Data | Accuracy | Precision | Recall | F1 score |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "|    0     |  0.848   |    0.9    | 0.831  |  0.864   |\n",
      "|    1     |  0.821   |   0.895   | 0.785  |  0.836   |\n",
      "|    2     |   0.83   |   0.926   | 0.769  |   0.84   |\n",
      "|    3     |  0.775   |   0.898   | 0.688  |  0.779   |\n",
      "|    4     |   0.82   |   0.923   |  0.75  |  0.828   |\n",
      "|   Avg    |  0.819   |   0.908   | 0.764  |  0.829   |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "RESULST FOR CLASS: BOTNET_RBOT\n",
      "### Model Name: LOF2  ###\n",
      "323 168\n",
      "+----------+----------+-----------+--------+----------+\n",
      "| Mix Data | Accuracy | Precision | Recall | F1 score |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "|    0     |  0.318   |   0.272   | 0.862  |  0.413   |\n",
      "|    1     |  0.279   |   0.239   | 0.723  |  0.359   |\n",
      "|    2     |  0.322   |   0.271   | 0.846  |   0.41   |\n",
      "|    3     |  0.319   |   0.267   | 0.844  |  0.406   |\n",
      "|    4     |  0.315   |   0.264   | 0.828  |   0.4    |\n",
      "|   Avg    |   0.31   |   0.262   | 0.821  |  0.398   |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "RESULST FOR CLASS: BOTNET_NERIS\n",
      "### Model Name: LOF2  ###\n",
      "323 400\n",
      "+----------+----------+-----------+--------+----------+\n",
      "| Mix Data | Accuracy | Precision | Recall | F1 score |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "|    0     |  0.523   |   0.514   | 0.862  |  0.644   |\n",
      "|    1     |  0.515   |   0.511   | 0.738  |  0.604   |\n",
      "|    2     |  0.531   |   0.522   | 0.738  |  0.611   |\n",
      "|    3     |  0.555   |   0.535   | 0.844  |  0.655   |\n",
      "|    4     |  0.508   |   0.506   | 0.656  |  0.571   |\n",
      "|   Avg    |  0.526   |   0.517   | 0.768  |  0.617   |\n",
      "+----------+----------+-----------+--------+----------+\n",
      "0.749\n"
     ]
    }
   ],
   "source": [
    "SRC_CLASS = \"IP_CAM\"\n",
    "src_f1_score = []\n",
    "t = Pull(DATA_CLASS[SRC_CLASS],1)\n",
    "for data_cl in DATA_CLASS:\n",
    "   # if data_cl == SRC_CLASS:\n",
    "   #     continue\n",
    "    a = Pull(DATA_CLASS[data_cl],1)\n",
    "    print(\"RESULST FOR CLASS:\",data_cl)\n",
    "    if data_cl == SRC_CLASS:\n",
    "        runModel(MODELS[\"LOF\"])\n",
    "    else:\n",
    "        src_f1_score.append(runModel(MODELS[\"LOF\"]))\n",
    "#print(src_f1_score)\n",
    "print(round(mean(src_f1_score),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Models\n",
    "Used for independet testing with any part of provided dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolated Forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Create Model\n",
    "rng = np.random.RandomState(12345)\n",
    "clf = IsolationForest(n_estimators = 100, max_samples=\"auto\",max_features=1,bootstrap=False ,random_state=rng, behaviour='new', contamination='auto')\n",
    "\n",
    "kf = KFold(3, True)\n",
    "t_data = np.array(t.data)\n",
    "a_data = np.array(a.data)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(t_data):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    clf.fit(t_data[train_index])\n",
    "    #Evaluate \n",
    "    y_pred_valid = clf.predict(t_data[test_index])\n",
    "    y_pred_outliers = clf.predict(a.data)\n",
    "    print(\"===== Iteration:\",iteration_cnt,\"=====\")\n",
    "    #print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"Valid\")\n",
    "    #print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"Anomaly\")\n",
    "    #Concatenate above results from anomaly and valid dataset for clearer results\n",
    "    print_metrics([1]*len(y_pred_valid)+[-1]*len(y_pred_outliers),np.concatenate((y_pred_valid,y_pred_outliers),axis=None),label=\"Mix\")\n",
    "    \n",
    "    #m_valid.update([1]*len(y_pred_valid),y_pred_valid)\n",
    "    #m_anomaly.update([-1]*len(y_pred_outliers),y_pred_outliers)\n",
    "    #m_valid.print()\n",
    "    #m_anomaly.print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOF Novelty"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Create Model\n",
    "clf = LocalOutlierFactor(n_neighbors = 10, metric = \"minkowski\", novelty=True, contamination='auto')\n",
    "\n",
    "kf = KFold(3, True)\n",
    "t_data = np.array(t.data)\n",
    "a_data = np.array(a.data)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(t_data):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    clf.fit(t_data[train_index])\n",
    "    #Evaluate \n",
    "    y_pred_valid = clf.predict(t_data[test_index])\n",
    "    y_pred_outliers = clf.predict(a.data)\n",
    "    print(\"===== Iteration:\",iteration_cnt,\"=====\")\n",
    "    #print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"Valid\")\n",
    "    #print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"Anomaly\")\n",
    "    #Concatenate above results from anomaly and valid dataset for clearer results\n",
    "    print_metrics([1]*len(y_pred_valid)+[-1]*len(y_pred_outliers),np.concatenate((y_pred_valid,y_pred_outliers),axis=None),label=\"Mix\")\n",
    "    score_v = clf.decision_function(t_data[test_index])\n",
    "    score_a = clf.decision_function(a.data)\n",
    "    cnt = 0\n",
    "    for i in score_a:\n",
    "        if i < -10 :\n",
    "            cnt += 1\n",
    "    #print(cnt)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneClassSVM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Create Model\n",
    "clf = OneClassSVM(kernel='sigmoid',gamma=\"auto\",coef0=0.0, nu=0.1)\n",
    "\n",
    "kf = KFold(3, True)\n",
    "t_data = np.array(t.data)\n",
    "a_data = np.array(a.data)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(t_data):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    clf.fit(t_data[train_index])\n",
    "    #Evaluate \n",
    "    y_pred_valid = clf.predict(t_data[test_index])\n",
    "    y_pred_outliers = clf.predict(a.data)\n",
    "    print(\"===== Iteration:\",iteration_cnt,\"=====\")\n",
    "    #print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"Valid\")\n",
    "    #print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"Anomaly\")\n",
    "    #Concatenate above results from anomaly and valid dataset for clearer results\n",
    "    print_metrics([1]*len(y_pred_valid)+[-1]*len(y_pred_outliers),np.concatenate((y_pred_valid,y_pred_outliers),axis=None),label=\"Mix\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
